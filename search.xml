<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Spring的启动过程源码分析</title>
    <url>/2019/07/24/Spring%E7%9A%84%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<p>​        Spring有很强的拓展性，因此Spring有很强的生态，对Spring的深入理解可以提升开发在工作的效率，同时也可以学到更多Spring的代码思想，本文就是笔者最近读Spring源码之Spring启动过程的一点点个人理解，有些地方难免会出现理解不到位，希望大家多多指正。</p>
<p><strong>Spring的启动过程-Refresh方法</strong></p>
<p>​        我阅读的源码版本是 4.3.6.RELEASE，不算比较新，但对于Spring的启动过程的理解算是绰绰有余，下面贴的是一段Spring启动过程中核心代码Refresh过程。</p>
<a id="more"></a>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void refresh() throws BeansException, IllegalStateException &#123;   </span><br><span class="line">	synchronized (this.startupShutdownMonitor) &#123;      </span><br><span class="line">	// Prepare this context for refreshing.      </span><br><span class="line">	  prepareRefresh();   </span><br><span class="line">    </span><br><span class="line">	// Tell the subclass to refresh the internal bean factory.      				            ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();   </span><br><span class="line">    </span><br><span class="line">	// Prepare the bean factory for use in this context.         							   prepareBeanFactory(beanFactory);   </span><br><span class="line">    </span><br><span class="line">	try &#123;         </span><br><span class="line">	// Allows post-processing of the bean factory in context subclasses.         		        postProcessBeanFactory(beanFactory);</span><br><span class="line">    </span><br><span class="line">	// Invoke factory processors registered as beans in the context.         			        invokeBeanFactoryPostProcessors(beanFactory); </span><br><span class="line">    </span><br><span class="line">    // Register bean processors that intercept bean creation.                                    registerBeanPostProcessors(beanFactory); </span><br><span class="line">    </span><br><span class="line">    // Initialize message source for this context.         </span><br><span class="line">       initMessageSource();</span><br><span class="line">       </span><br><span class="line">    // Initialize event multicaster for this context.                     			            initApplicationEventMulticaster(); </span><br><span class="line">    </span><br><span class="line">    // Initialize other special beans in specific context subclasses.                            onRefresh(); </span><br><span class="line">    </span><br><span class="line">    // Check for listener beans and register them.        </span><br><span class="line">       registerListeners();  </span><br><span class="line">       </span><br><span class="line">    // Instantiate all remaining (non-lazy-init) singletons.                                    finishBeanFactoryInitialization(beanFactory);</span><br><span class="line">    </span><br><span class="line">    // Last step: publish corresponding event.         </span><br><span class="line">       finishRefresh();</span><br><span class="line">       </span><br><span class="line">     &#125;catch (BeansException ex) &#123;         </span><br><span class="line">      if (logger.isWarnEnabled()) &#123;            </span><br><span class="line">        logger.warn(&quot;Exception encountered during context initialization - &quot; +                  &quot;cancelling refresh attempt: &quot; + ex);         </span><br><span class="line">     &#125;        </span><br><span class="line">     // Destroy already created singletons to avoid dangling resources.         				destroyBeans();</span><br><span class="line">     </span><br><span class="line">     // Reset &apos;active&apos; flag.         </span><br><span class="line">     	cancelRefresh(ex);</span><br><span class="line">        </span><br><span class="line">     // Propagate exception to caller.         </span><br><span class="line">     		throw ex;      </span><br><span class="line">    &#125;finally &#123;         </span><br><span class="line">    // Reset common introspection caches in Spring&apos;s core, since we         </span><br><span class="line">    // might not ever need metadata for singleton beans anymore...         						resetCommonCaches();      </span><br><span class="line">    &#125;    </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下面我们对Spring的核心方法refresh（）进行分析：</p>
<p><strong>1、prepareRefresh()【刷新前的预处理】</strong> </p>
<p>​        1）设置开始时间</p>
<p>​        2）容器激活标志设置</p>
<p>​        3）initPropertySources()； 初始化一些属性设置；子类自定义个性化的属性设置方法</p>
<p>​        4）getEnvironment().validateRequiredProperties()；验证属性的合法等；</p>
<p>​        5）this.earlyApplicationEvents = new LinkedHashSet<applicationevent>()；保存容器中的一些早期事件；</applicationevent></p>
<p><strong>2、obtainFreshBeanFactory(); 获取BeanFactory</strong></p>
<p>​        1）refreshBeanFactory(); 刷新【创建】BeanFactory</p>
<p>​        2）getBeanFactory(); 返回刚才GenericApplicationContext创建的BeanFactory对象；</p>
<p>​        3）将创建的BeanFactory【DefaultListableBeanFactory】返回；</p>
<p><strong>3、prepareBeanFactory(beanFactory);BeanFactory的预准备工作【BeanFactory进行一些设置】</strong></p>
<p>​        1) 设置BeanFactory的类加载器，支持表达式解析器</p>
<p>​        2）添加部分BeanPostProcessor【 ApplicationContextAwareProcessor】</p>
<p>​        3）设置忽略自动装配接口；</p>
<p>【EnvironmentAware，EmbeddedValueResolverAware，ResourceLoaderAware，xxxAware】</p>
<p>​        4）设置可以解析的自动装配，我们能在任何组件中自动注入；</p>
<p>​      【BeanFactory，ResourceLoader，ApplicationEventPublisher，ApplicationContext】</p>
<p>​        5）添加BeanPostProcessor【ApplicationListenerDetector】</p>
<p>​        6）添加编译时的AspectJ；</p>
<p>​        7）给BeanFactory中注册一些能用的组件</p>
<p>​                environment【ConfigurableEnvironment】，</p>
<p>​                systemProperties【Map<string , object>】,</string></p>
<p>​                systemEnvironment【Map<string , object>】</string></p>
<p><strong>4、postProcessBeanFactory(beanFactory); BeanFactory准备工作完成后进行的后置处理工作</strong></p>
<p>​        子类通过重写这个方法在BeanFactory创建并预处理完成后做进一步设置。</p>
<p>=======================================================</p>
<p>​      ========<strong>=以上是BeanFactory的创建以及预处理准备工作</strong>=========</p>
<p>=======================================================</p>
<p><strong>5、invokeBeanFactoryPostProcessors(beanFactory);执行BeanFactory的后置处理器</strong></p>
<p>​        BeanFactoryPostProcessor：BeanFactory的后置处理器。在Bean标准初始化之后执行；</p>
<p>​        两个接口：BeanFactoryPostProcessor、BeanDefinitionRegisterPostProcessor</p>
<p>​            1）执行BeanFactoryPostProcessor的方法，先执行BeanDefinitionRegisterPostProcessor</p>
<p>​                    1.1）、获取所有的BeanDefinitionRegistryPostProcessor；</p>
<p>​                    1.2）、看先执行实现了PriorityOrdered优先级接口的BeanDefinitionRegistryPostProcessor；</p>
<p>​                                postProcessBeanDefinitionRegistry(registry);</p>
<p>​                    1.3）、在执行实现了Ordered顺序接口的BeanDefinitionRegistryPostProcessor</p>
<p>​                             postProcessBeanDefinitionRegistry(registry);</p>
<p>​                    1.4）、最后执行没有实现任何优先级或者顺序接口的BeanDefinitionRegistryPostProcessor；</p>
<p>​                                postProcessBeanDefinitionRegistry(registry);</p>
<p>​            2）在执行BeanFactoryPostProcessor的方法</p>
<p>​                    2.1）、获取所有的BeanFactoryPostProcessor；</p>
<p>​                    2.2）、看先执行实现了PriorityOrdered优先级接口的BeanFactoryPostProcessor；</p>
<p>​                                postProcessor.postProcessBeanFactory(beanFactory);</p>
<p>​                    2.3）、在执行实现了Ordered顺序接口的BeanFactoryPostProcessor；</p>
<p>​                                postProcessor.postProcessBeanFactory(beanFactory);</p>
<p>​                    2.4）、最后执行没有实现任何优先级或者顺序接口的BeanFactoryPostProcessor；</p>
<p>​                                postProcessor.postProcessBeanFactory(beanFactory);</p>
<p><strong>6、registerBeanPostProcessors(beanFactory); 【注册Bean的后置处理器】</strong></p>
<p>​        1）获取所有的BeanPostProcessor；后置处理器默认可以通过PriorityOrdered、Ordered接口来执行优先级。</p>
<p>​        2）先注册PriorityOrdered优先级接口的BeanPostProcessor；</p>
<p>​                把每一个BeanPostProcessor添加到BeanFactory中beanFactory.addBeanPostProcessor(postProcessor);</p>
<p>​        3）再注册Orered优先级接口的BeanPostProcessor；</p>
<p>​                把每一个BeanPostProcessor添加到BeanFactory中beanFactory.addBeanPostProcessor(postProcessor)</p>
<p>​        4）最后注册没有实现任何接口优先级接口的BeanPostProcessor</p>
<p>​        5）最终注册一个ApplicationListenerDetector添加到BeanFactory</p>
<p><strong>7、initMessageSource();初始化MessageSource组件【做国际化功能；消息绑定，消息解析】</strong></p>
<p>​        1）获取BeanFactory</p>
<p>​        2）看容器中是否有id为messageSource的，类型是MessageSource的组件，如果有赋值给MessageSource，如果没有自己创建一个DelegatingMessageSource()</p>
<p>​        3）把创建好的MessageSource注册到容器中，以后获取国际化配置文件值的时候，可以自动注入MessageSource；beanFactory.registerSingleton(MESSAGE_SOURCE_BEAN_NAME, this.messageSource);</p>
<p><strong>8、initApplicationEventMulticaster();初始化事件派发器</strong></p>
<p>​        1）获取BeanFactory</p>
<p>​        2）看容器中是否有id为applicationEventMulticaster的的组件，有从容器中获取ApplicationEventMulticaster的ApplicationEventMulticaster</p>
<p>​        3）如果上一步没有配置好，那么new SimpleApplicationEventMulticaster(beanFactory);</p>
<p>​        4）把创建好的SimpleApplicationEventMulticaster注册到容器中，以后获取可以自动注入</p>
<p><strong>9、onRefresh（）；模板方法里面的钩子方法，留给子容器</strong></p>
<p>​        子类重写这个方法，在容器刷新的时候可以自定义逻辑。</p>
<p><strong>10、registerlisteners();注册监听器；所有项目里面的ApplicationListen注册到容器中</strong></p>
<p>​        1）获取所有的ApplicationListener</p>
<p>​        2）将每个监听器添加到事件派发器中：</p>
<p>getApplicationEventMulticaster().addApplicationListener(listener);</p>
<p>​        3）派发之前步骤产生的事件。getApplicationEventMulticaster().multicastEvent(earlyEvent);</p>
<p><strong>10、finishBeanFactoryInitialization(beanFactory);初始化所有剩下的单实例Bean</strong>（很重要，但是很复杂）</p>
<p>  可以参考博客，这位大佬解释的很全：<a href="https://blog.csdn.net/nuomizhende45/article/details/81158383" target="_blank" rel="noopener">https://blog.csdn.net/nuomizhende45/article/details/81158383</a></p>
<p><strong>11、finishRefresh();完成刷新</strong></p>
<p>​        1）initLifecycleProcessor(); 初始化和生命周期有关的后置处理器LifecycleProcessor</p>
<p>​        2）getLifecycleProcessor().onRefresh();拿到前面定义的生命周期处理器（BeanFactory），回调OnRefresh</p>
<p>​        3）publishEvent(new ContextRefreshedEvent(this));发布容器刷新事件完成。</p>
<p>​        4）LiveBeansView.registerApplicationContext(this);</p>
]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title>DevOps</title>
    <url>/2019/05/27/DevOps/</url>
    <content><![CDATA[<h3 id="谈谈对docker的理解？"><a href="#谈谈对docker的理解？" class="headerlink" title="谈谈对docker的理解？"></a>谈谈对docker的理解？</h3><p>​    <strong>什么是docker？</strong></p>
<p>docker的思想来源于集装箱，试问集装箱解决了什么问题？<br>试想，在一艘大船上，可以把货物规整的摆放起来。并且各种各样的货物被集装箱标准化了，集装箱和集装箱之间不会相互影响。那么我就不需要专门运送水果的船和专门运送化学物品的船了。只要这些货物在集装箱里装的好好的，那我就可以用一艘大船把它们都运走。docker就是类似的理念。现在都流行云计算了，云计算就好比大货轮，而docker就是集装箱。</p>
<p>docker基于go语言开发，之所以被称为容器技术，是因为docker对进程进行封装，隔离于宿主系统和其它的进程，类似于一个装东西的容器，而且在容器里面装有一系列文件系统、网络、依赖包等应用程序运行需要的环境，开发人员可以快速将他们的应用程序部署到容器内运行，docker是基于操作系统的虚拟化技术。</p>
<p>​    <strong>docker解决了什么问题？</strong></p>
<p>1.更快速地交付和部署</p>
<p>2.更轻松的迁移和扩展</p>
<p>3.更高效的虚拟化和更简单的管理</p>
<a id="more"></a>
<p>​    <strong>docker的架构？</strong></p>
<p><strong>Docker Client:</strong> 用户通过Docker Client与Docker Daemon进行通信，利用命令行发送创建镜像、运行容器之类的请求。</p>
<p><strong>Docker Daemon：</strong>Docker Daemon是Docker架构中一个常驻在后台的系统进程，接受并处理Docker Client发送的请求。该守护进程在后台启动了一个Server，Server负责接受Docker Client发送的请求；然后通过路由与分发调度，找到相应的Handler来执行请求。</p>
<p><strong>Docker Registry：</strong>存储容器镜像的仓库</p>
<p>​    <strong>docker的三个核心概念？</strong></p>
<p><strong>容器</strong>：具体的运行应用程序的一个进程，它里面包含应用程序的各种依赖。</p>
<p><strong>镜像</strong>：创建容器的模板，根据不同配置的镜像来创建不同的容器使用。镜像和容器的关系可以理解为面向对象中类和实例对象的关系。</p>
<p><strong>仓库</strong>：一个镜像只可以创建一种类型的容器，镜像多了就需要放到镜像仓库中存起来，仓库有本地镜像仓库和公共镜像仓库，平时使用本地仓库的镜像，没有的话去Registry hub公共镜像仓库下载。</p>
<hr>
<h3 id="docker的网络模型？"><a href="#docker的网络模型？" class="headerlink" title="docker的网络模型？"></a>docker的网络模型？</h3><p>. <strong>host模式（主机模式）</strong>，使用–net=host指定。<br>启动容器的时候使用host模式，那么这个容器将不会获得一个独立的Network Namespace，而是和宿主机共用一个Network Namespace。容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口</p>
<p><strong>· container模式（容器模式）</strong>，使用–net=container:NAME_or_ID指定。<br>在理解了host模式后，这个模式也就好理解了。这个模式指定新创建的容器和已经存在的一个容器共享一个Network Namespace，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的IP，而是和一个指定的容器共享IP、端口范围等</p>
<p>· <strong>none模式</strong>，使用–net=none指定。<br>这种模式下，Docker容器拥有自己的Network Namespace，但是，并不为Docker容器进行任何网络配置。也就是说，这个Docker容器没有网卡、IP、路由等信息。需要我们自己为Docker容器添加网卡、配置IP等。</p>
<p><strong>· bridge模式（桥接）</strong>，使用–net=bridge指定，默认设置。<br>网桥进行交互,会去生成一个子网络,子网络的每个子网络中的ip都是一个单独的网络,一个自己的IP段，此模式会为每一个容器分配Network Namespace、设置IP等，并将一个主机上的Docker容器连接到一个虚拟网桥上。</p>
<hr>
<h3 id="docker路由互联，Openvswitch"><a href="#docker路由互联，Openvswitch" class="headerlink" title="docker路由互联，Openvswitch"></a>docker路由互联，Openvswitch</h3><p>openvswitch是一个虚拟交换软件，主要用于虚拟机VM环境，作为一个虚拟交换机，支持Xen/XenServer，KVM以及virtualBox多种虚拟化技术。在这种虚拟化的环境中，一个虚拟交换机主要有两个作用：传递虚拟机之间的流量，以及实现虚拟机和外界网络的通信。</p>
<hr>
<h3 id="k8s的各组件的作用？"><a href="#k8s的各组件的作用？" class="headerlink" title="k8s的各组件的作用？"></a>k8s的各组件的作用？</h3><h5 id="Master：是集群的网关和中枢枢纽，主要作用：暴露API接口，跟踪其他服务器的健康状态、以最优方式调度负载，以及编排其他组件之间的通信。单个的Master节点可以完成所有的功能，但是考虑单点故障的痛点，生产环境中通常要部署多个Master节点，组成Cluster。"><a href="#Master：是集群的网关和中枢枢纽，主要作用：暴露API接口，跟踪其他服务器的健康状态、以最优方式调度负载，以及编排其他组件之间的通信。单个的Master节点可以完成所有的功能，但是考虑单点故障的痛点，生产环境中通常要部署多个Master节点，组成Cluster。" class="headerlink" title="Master：是集群的网关和中枢枢纽，主要作用：暴露API接口，跟踪其他服务器的健康状态、以最优方式调度负载，以及编排其他组件之间的通信。单个的Master节点可以完成所有的功能，但是考虑单点故障的痛点，生产环境中通常要部署多个Master节点，组成Cluster。"></a>Master：是集群的网关和中枢枢纽，主要作用：暴露API接口，跟踪其他服务器的健康状态、以最优方式调度负载，以及编排其他组件之间的通信。单个的Master节点可以完成所有的功能，但是考虑单点故障的痛点，生产环境中通常要部署多个Master节点，组成Cluster。</h5><p><strong>1、API Server</strong><br>K8S对外的唯一接口，提供HTTP/HTTPS RESTful API，即kubernetes API。所有的请求都需要经过这个接口进行通信。主要负责接收、校验并响应所有的REST请求，结果状态被持久存储在etcd当中，所有资源增删改查的唯一入口。</p>
<p><strong>2、etcd</strong><br>负责保存k8s 集群的配置信息和各种资源的状态信息，当数据发生变化时，etcd会快速地通知k8s相关组件。etcd是一个独立的服务组件，并不隶属于K8S集群。生产环境当中etcd应该以集群方式运行，以确保服务的可用性。</p>
<p>etcd不仅仅用于提供键值数据存储，而且还为其提供了监听（watch）机制，用于监听和推送变更。在K8S集群系统中，etcd的键值发生变化会通知倒API Server，并由其通过watch API向客户端输出。</p>
<p><strong>3、Controller Manager</strong><br>负责管理集群各种资源，保证资源处于预期的状态。Controller  Manager由多种controller组成，包括replication controller、endpoints  controller、namespace controller、serviceaccounts controller等  。由控制器完成的主要功能主要包括生命周期功能和API业务逻辑，具体如下：<br>生命周期功能：包括Namespace创建和生命周期、Event垃圾回收、Pod终止相关的垃圾回收、级联垃圾回收及Node垃圾回收等。<br>API业务逻辑：例如，由ReplicaSet执行的Pod扩展等。</p>
<p><strong>4、调度器（Schedule）</strong><br>资源调度，负责决定将Pod放到哪个Node上运行。Scheduler在调度时会对集群的结构进行分析，当前各个节点的负载，以及应用对高可用、性能等方面的需求。</p>
<h5 id="Node：是Kubernetes的工作节点，负责接收来自Master的工作指令，并根据指令相应地创建和销毁Pod对象，以及调整网络规则进行合理路由和流量转发。生产环境中，Node节点可以有N个。"><a href="#Node：是Kubernetes的工作节点，负责接收来自Master的工作指令，并根据指令相应地创建和销毁Pod对象，以及调整网络规则进行合理路由和流量转发。生产环境中，Node节点可以有N个。" class="headerlink" title="Node：是Kubernetes的工作节点，负责接收来自Master的工作指令，并根据指令相应地创建和销毁Pod对象，以及调整网络规则进行合理路由和流量转发。生产环境中，Node节点可以有N个。"></a>Node：是Kubernetes的工作节点，负责接收来自Master的工作指令，并根据指令相应地创建和销毁Pod对象，以及调整网络规则进行合理路由和流量转发。生产环境中，Node节点可以有N个。</h5><p><strong>1、Kubelet</strong><br>kubelet是node的agent，当Scheduler确定在某个Node上运行Pod后，会将Pod的具体配置信息（image、volume等）发送给该节点的kubelet，kubelet会根据这些信息创建和运行容器，并向master报告运行状态。</p>
<p><strong>2、Container Runtime（docker）</strong><br>每个Node都需要提供一个容器运行时（Container Runtime）环境，它负责下载镜像并运行容器。目前K8S支持的容器运行环境至少包括Docker、RKT、cri-o、Fraki等。</p>
<p><strong>3、Kube-proxy</strong><br>service在逻辑上代表了后端的多个Pod，外借通过service访问Pod。service接收到请求就需要kube-proxy完成转发到Pod的。每个Node都会运行kube-proxy服务，负责将访问的service的TCP/UDP数据流转发到后端的容器，如果有多个副本，kube-proxy会实现负载均衡，有2种方式：LVS或者Iptables。</p>
<hr>
<h3 id="怎么让服务运行在master节点上？"><a href="#怎么让服务运行在master节点上？" class="headerlink" title="怎么让服务运行在master节点上？"></a>怎么让服务运行在master节点上？</h3><p>使用kubeadm部署的kubernetes集群，其master节点默认拒绝将pod调度运行于其上的，加点官方的术语就是：master默认被赋予了一个或者多个“污点（taints）”，“污点”的作用是让该节点拒绝将pod调度运行于其上。那么存在某些情况，比如想让master也成为工作节点可以调度pod运行怎么办呢？</p>
<p>两种方式：①去掉“污点”（taints）【生产环境不推荐】；②让pod能够容忍（tolerations）该节点上的“污点”。</p>
]]></content>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title>解决k8s初始化问题</title>
    <url>/2019/05/12/%E8%A7%A3%E5%86%B3k8s%E9%9B%86%E7%BE%A4kubeadm%20init%E5%88%9D%E5%A7%8B%E5%8C%96%E9%95%9C%E5%83%8Fpull%E4%B8%8D%E4%B8%8B%E6%9D%A5%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p> 新版本的Kubernetes在安装部署中，需要从k8s.grc.io仓库中拉取所需镜像文件，但由于国内网络防火墙问题导致无法正常拉取。</p>
<h1 id="kubeadm-init-所出现的问题："><a href="#kubeadm-init-所出现的问题：" class="headerlink" title="kubeadm init 所出现的问题："></a>kubeadm init 所出现的问题：</h1><pre><code>[preflight] Some fatal errors occurred:
    [ERROR ImagePull]: failed to pull image [k8s.gcr.io/kube-apiserver-amd64:v1.11.2]: exit status 1
    [ERROR ImagePull]: failed to pull image [k8s.gcr.io/kube-controller-manager-amd64:v1.11.2]: exit status 1
    [ERROR ImagePull]: failed to pull image [k8s.gcr.io/kube-scheduler-amd64:v1.11.2]: exit status 1
    [ERROR ImagePull]: failed to pull image [k8s.gcr.io/kube-proxy-amd64:v1.11.2]: exit status 1
    [ERROR ImagePull]: failed to pull image [k8s.gcr.io/pause:3.1]: exit status 1
    [ERROR ImagePull]: failed to pull image [k8s.gcr.io/etcd-amd64:3.2.18]: exit status 1
    [ERROR ImagePull]: failed to pull image [k8s.gcr.io/coredns:1.1.3]: exit status 1
</code></pre><a id="more"></a>
<h2 id="解决方法："><a href="#解决方法：" class="headerlink" title="解决方法："></a>解决方法：</h2><pre><code>#!/bin/bash
K8S_VERSION=v1.13.1
ETCD_VERSION=3.2.24
DASHBOARD_VERSION=v1.8.3
FLANNEL_VERSION=v0.10.0-amd64
DNS_VERSION=1.2.0
PAUSE_VERSION=3.1
# 基本组件
docker pull mirrorgooglecontainers/kube-apiserver-amd64:$K8S_VERSION
docker pull mirrorgooglecontainers/kube-controller-manager-amd64:$K8S_VERSION
docker pull mirrorgooglecontainers/kube-scheduler-amd64:$K8S_VERSION
docker pull mirrorgooglecontainers/kube-proxy-amd64:$K8S_VERSION
docker pull mirrorgooglecontainers/etcd-amd64:$ETCD_VERSION
docker pull mirrorgooglecontainers/pause:$PAUSE_VERSION
docker pull coredns/coredns:$DNS_VERSION

# 网络组件
docker pull quay.io/coreos/flannel:$FLANNEL_VERSION

# 修改tag
docker tag mirrorgooglecontainers/kube-apiserveramd64:$K8S_VERSION k8s.gcr.io/kube-apiserver-amd64:$K8S_VERSION
docker tag mirrorgooglecontainers/kube-controller-manageramd64:$K8S_VERSION k8s.gcr.io/kube-controller-manager-amd64:$K8S_VERSION
docker tag mirrorgooglecontainers/kube-scheduleramd64:$K8S_VERSION k8s.gcr.io/kube-scheduler-amd64:$K8S_VERSION
docker tag mirrorgooglecontainers/kube-proxyamd64:$K8S_VERSION k8s.gcr.io/kube-proxy-amd64:$K8S_VERSION
docker tag mirrorgooglecontainers/etcd-amd64:$ETCD_VERSION k8s.gcr.io/etcd-amd64:$ETCD_VERSION
docker tag mirrorgooglecontainers/pause:$PAUSE_VERSION k8s.gcr.io/pause:$PAUSE_VERSION
docker tag coredns/coredns:$DNS_VERSION k8s.gcr.io/coredns:$DNS_VERSION

#删除冗余的images
docker rmi mirrorgooglecontainers/kube-apiserver-amd64:$K8S_VERSION
docker rmi mirrorgooglecontainers/kube-controller-manager-amd64:$K8S_VERSION
docker rmi mirrorgooglecontainers/kube-scheduler-amd64:$K8S_VERSION
docker rmi mirrorgooglecontainers/kube-proxy-amd64:$K8S_VERSION
docker rmi mirrorgooglecontainers/etcd-amd64:$ETCD_VERSION
docker rmi mirrorgooglecontainers/pause:$PAUSE_VERSION
docker rmi coredns/coredns:$DNS_VERSION
</code></pre>]]></content>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>The connection to the server localhost:8080 was refused - did you specify the right host or port?</title>
    <url>/2019/05/12/The%20connection%20to%20the%20server%20localhost8080%20was%20refused%20-%20did%20you%20specify%20the%20right%20host%20or%20port/</url>
    <content><![CDATA[<h2 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h2><p><img src="/.com//k8s/k8s001.png" alt></p>
<pre><code>出现这个问题的原因是kubectl命令需要使用kubernetes-admin来运行
</code></pre><h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h3><blockquote>
<p>1、 将主节点（master节点）中的【/etc/kubernetes/admin.conf】文件拷贝到从节点相同目录下:</p>
</blockquote>
<blockquote>
<pre><code>scp -r /etc/kubernetes/admin.conf ${node1}:/etc/kubernetes/admin.conf
</code></pre></blockquote>
<blockquote>
<p>2、 配置环境变量：</p>
</blockquote>
<pre><code>echo &quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot; &gt;&gt; ~/.bash_profile
</code></pre><blockquote>
<p>3、 立即生效：</p>
<pre><code>source ~/.bash_profile
</code></pre></blockquote>
<h2 id="具体操作截图"><a href="#具体操作截图" class="headerlink" title="具体操作截图"></a>具体操作截图</h2><p><img src="/.com//k8s/k8s002.png" alt></p>
]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOs7中快速彻底搞定Docker-ce版的卸载与指定版本的安装</title>
    <url>/2019/05/12/CentOs7%E4%B8%AD%E5%BF%AB%E9%80%9F%E5%BD%BB%E5%BA%95%E6%90%9E%E5%AE%9ADocker-ce%E7%89%88%E7%9A%84%E5%8D%B8%E8%BD%BD%E4%B8%8E%E6%8C%87%E5%AE%9A%E7%89%88%E6%9C%AC%E7%9A%84%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p> 平时安装docker的时候可能会遇到docker版本与自己的预期的版本不相符，今天博主给分享一下自己曾今遇到过的坑：</p>
<h3 id="docker的卸载："><a href="#docker的卸载：" class="headerlink" title="docker的卸载："></a>docker的卸载：</h3><blockquote>
<p>1、列出docker安装过的相关包：</p>
</blockquote>
<pre><code>sudo yum list installed | grep docker
</code></pre><blockquote>
</blockquote>
<p><img src="/.com//docker/docker01.jpg" alt></p>
<blockquote>
<p>2、删除相关安装包</p>
</blockquote>
<pre><code>sudo yum -y remove docker-ce.x86_64  
sudo yum -y remove docker-ce-selinux.noarch`
</code></pre><blockquote>
<p>3、删除相关的镜像与容器</p>
</blockquote>
<pre><code>sudo rm -rf /var/lib/docker
</code></pre><a id="more"></a>
<h3 id="docker特定版本的安装"><a href="#docker特定版本的安装" class="headerlink" title="docker特定版本的安装"></a>docker特定版本的安装</h3><blockquote>
<p>centOs安装最新的docker-ce版：</p>
</blockquote>
<pre><code>yum install docker -y 
安装指定的dcker版本，需要如下几步：
1、 yum install -y yum-utils device-mapper-persistent-data lvm2
2、 yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
3、 yum install docker-ce-17.03.3.ce -y
如果提示container-selinux依赖问题，先安装ce-17.03匹配版本，再去执行第3步即可：
   yum localinstall https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-selinux-17.03.3.ce-1.el7.noarch.rpm
4、启动docker，并设置为开机自启
  systemctl start docker &amp;&amp; systemctl enable docker 
</code></pre><p>注意：在搭建集群或者多台物理机需要安装docker时，为了方便可以把docker特定版本的安装步骤写成一个安装脚本，然后在分别去执行脚本即可完成安装：</p>
<blockquote>
<p>1、首先创建一个install-docker-ce-17.03.3.ce.sh的脚本（随便什么命名都可以，为了便于理解写成docker的版本号）</p>
<pre><code>vim install-docker-ce-17.03.3.ce.sh
</code></pre></blockquote>
<blockquote>
<p>2、创建的install-docker-ce-17.03.3.ce.sh脚本内容如下：</p>
</blockquote>
<pre><code>#!/bin/sh
yum install -y yum-utils device-mapper-persistent-data lvm2 \
&amp;&amp; yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo -y \
&amp;&amp; yum localinstall https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-selinux-17.03.3.ce-1.el7.noarch.rpm -y \
&amp;&amp; yum install docker-ce-17.03.3.ce -y \
&amp;&amp; systemctl start docker \
&amp;&amp; systemctl enable docker
</code></pre><blockquote>
<p>3、添加脚本可执行权限：</p>
</blockquote>
<pre><code>chmod +x install-docker-ce-17.03.3.ce.sh
</code></pre><blockquote>
<p>4、执行脚本</p>
</blockquote>
<pre><code>./install-docker-ce-17.03.3.ce.sh
</code></pre>]]></content>
      <categories>
        <category>容器</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>浅谈Java -jar与Java -cp在Dockerfile的区别</title>
    <url>/2019/04/27/%E6%B5%85%E8%B0%88Java-jar%E4%B8%8EJava-cp%E5%9C%A8Dockerfile%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<p>首先看看Java -help的一张截图：<br><img src="/.com//other/java01.jpg" alt></p>
<pre><code>从截图截图可以看出Java命令运行一个程序的的两种用法：
用法: java [-options] class [args...] (执行类) 
或者  java [-options] -jar jarfile [args...] (执行jar文件)
</code></pre><p>在使用docker制作镜像的时候，我们应该怎么编写上面java的两种用法的Dockfile呢？</p>
<h3 id="一、Dockerfile脚本"><a href="#一、Dockerfile脚本" class="headerlink" title="一、Dockerfile脚本"></a>一、Dockerfile脚本</h3><pre><code>touch  Dockerfile
或者 vim Dockerfile
</code></pre><p>方式一：使用java -jar的方式启动spring boot项目，把下面内容复制到刚创建的Dockerfile中</p>
<pre><code>FROM openjdk:8-jre-alpine
ADD  demo-docker-1.0.jar  /usr/local
CMD java  -Xms512m -Xmx512m  -jar /usr/local/demo-docker-1.0.jar
</code></pre><a id="more"></a>
<p>方式二：使用java -cp的方式启动spring boot项目，把下面内容复制到刚创建的Dockerfile中</p>
<pre><code>FROM openjdk:8-jre-alpine
CMD java  -cp /home/lfm/conf:/home/lfm/demo-docker-1.0.jar  -Xms512m -Xmx512m  org.springframework.boot.loader.JarLauncher
</code></pre><p>在服务器上创建存在jar与jar里面配置文件的文件夹：</p>
<pre><code>mkdir -p /home/lfm/conf
</code></pre><p><img src="/.com//other/java02.jpg" alt></p>
<h3 id="二、制作镜像"><a href="#二、制作镜像" class="headerlink" title="二、制作镜像"></a>二、制作镜像</h3><pre><code>docker build -t demo:1.0 .
</code></pre><p>备注：docker：镜像名 1.0：版本号   .：代表Dockerfile在当前路径 </p>
<h3 id="三、运行镜像（容器是镜像的运行实例）"><a href="#三、运行镜像（容器是镜像的运行实例）" class="headerlink" title="三、运行镜像（容器是镜像的运行实例）"></a>三、运行镜像（容器是镜像的运行实例）</h3><p> 方式一： spring boot项目的jar通过java -jar启动</p>
<pre><code>docker run -p 主机端口：容器端口 -v 主机挂载路径:容器数据卷的路径 -e 环境变量 --name 容器名 镜像名：版本号

例如：docker run -p 30080：8080 -v /home/data:/local --name demo demo:1.0
</code></pre><p>方式二：spring boot项目的jar通过java -cp启动</p>
<pre><code>docker run -p 主机端口：容器端口 -v 主机挂载路径:容器数据卷的路径  -e 环境变量 --name 容器名 镜像名：版本号

docker run -p 30080：8080 -v /home/lfm:/home/lfm --name demo demo:1.0
</code></pre><p>读到这里，细心的人会发现，通过java -cp启动Spring boot项目，运行镜像时候的数据挂载（-v /home/lfm:/home/lfm ）与Dockerfile里面脚本（java  -cp /home/lfm/conf:/home/lfm/demo-docker-1.0.jar）很相似。而通过java -jar方式启动的时候则不需要关心挂载路径问题。<br>所以说，通过java -cp的运行Spring boot项目jar，其实运行的镜像的容器只是一个运行jar的JDK容器环境，下面通过图解释这个问题。</p>
<p>java -jar的形式：<br><img src="/.com//other/java04.jpg" alt></p>
<p>java -cp的形式：<br><img src="/.com//other/java03.jpg" alt></p>
<p>如果公司测试环境是没有CICD流水线的单Docker环境或者个人迭代开发项目的情况下，使用jav -cp制作镜像，更新镜像的时候只需要更换相对主机应文件下的jar或者配置文件，然后重启容器即可。不需要重新制作镜像，避免很多麻烦。</p>
<h3 id="四、重启容器的简单方法"><a href="#四、重启容器的简单方法" class="headerlink" title="四、重启容器的简单方法"></a>四、重启容器的简单方法</h3><pre><code>docker ps -a |grep 容器名或者对外端口号（能唯一标识该容器即可）  |awk &apos;{print $1}&apos; |xargs docker restart 

例如：docker ps -a |grep 30080  |awk &apos;{print $1}&apos; |xargs docker restart 
</code></pre>]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>如何在Docker和k8s中批量删除不要的资源</title>
    <url>/2019/04/23/docker%E5%92%8Ck8s%E4%B8%AD%E6%89%B9%E9%87%8F%E5%88%A0%E9%99%A4%E4%B8%8D%E8%A6%81%E7%9A%84%E8%B5%84%E6%BA%90/</url>
    <content><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>经常玩Docker与K8s的朋友经常会遇到很多不是running的容器或者pod，其实这很浪费资源，下面主要介绍在Docker和K8s中批量删除不是running状态的容器或者pod。</p>
<a id="more"></a>
<h3 id="清理exited进程："><a href="#清理exited进程：" class="headerlink" title="清理exited进程："></a>清理exited进程：</h3><pre><code>方法一：
根据容器的状态，删除Exited状态的容器
docker rm $(docker ps -q -f status=exited)

方法二:
显示所有的容器，过滤出Exited状态的容器，取出这些容器的ID
sudo docker ps -a|grep Exited|awk &apos;{print $1}&apos;
查询所有的容器，过滤出Exited状态的容器，列出容器ID，删除这些容器
sudo docker rm `docker ps -a|grep Exited|awk &apos;{print $1}&apos;`
或者
docker ps -a|grep Exited|awk &apos;{print $1}&apos;|xargs docker rm

方法三：
删除所有未运行的容器（已经运行的删除不了，未运行的就一起被删除了）
sudo docker rm $(sudo docker ps -a -q)

方法四：Docker 1.13版本以后，可以使用 docker containers prune 命令，删除孤立的容器
sudo docker container prune
</code></pre><h3 id="清理dangling-volumes（可以参考清理exited进程的四种方法）："><a href="#清理dangling-volumes（可以参考清理exited进程的四种方法）：" class="headerlink" title="清理dangling volumes（可以参考清理exited进程的四种方法）："></a>清理dangling volumes（可以参考清理exited进程的四种方法）：</h3><pre><code>docker volume rm $(docker volume ls -qf dangling=true)
</code></pre><h3 id="清理dangling-image（可以参考清理exited进程的四种方法）："><a href="#清理dangling-image（可以参考清理exited进程的四种方法）：" class="headerlink" title="清理dangling image（可以参考清理exited进程的四种方法）："></a>清理dangling image（可以参考清理exited进程的四种方法）：</h3><pre><code>docker rmi $(docker images --filter &quot;dangling=true&quot; -q --no-trunc)
</code></pre><h3 id="清理MatchNodeSelector的pod（可以参考清理exited进程的四种方法）："><a href="#清理MatchNodeSelector的pod（可以参考清理exited进程的四种方法）：" class="headerlink" title="清理MatchNodeSelector的pod（可以参考清理exited进程的四种方法）："></a>清理MatchNodeSelector的pod（可以参考清理exited进程的四种方法）：</h3><pre><code>kubectl --all-namespaces  get po -o wdie | grep MatchNodeSelector |awk &apos;{print$1}&apos;|xargs kubectl -n kube-system delete pods
</code></pre>]]></content>
      <tags>
        <tag>Docker</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>离线搭建Docker镜像仓库harborda</title>
    <url>/2019/04/20/%E7%A6%BB%E7%BA%BF%E6%90%AD%E5%BB%BAdocker%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93harborda/</url>
    <content><![CDATA[<h1 id="1、说明"><a href="#1、说明" class="headerlink" title="1、说明"></a>1、说明</h1><p>搭建Harbor私有仓库来管理镜像，首先需要安装docker和docker-compose，本分主要介绍他们的离线搭建方式。</p>
<h1 id="2、搭建docker环境"><a href="#2、搭建docker环境" class="headerlink" title="2、搭建docker环境"></a>2、搭建docker环境</h1><p>docker安装不是本次介绍重点：<a href="https://www.cnblogs.com/anxminise/p/9690635.html" title="可以参考该博文进行安装" target="_blank" rel="noopener">https://www.cnblogs.com/anxminise/p/9690635.html</a></p>
<h1 id="3、搭建docker-compose"><a href="#3、搭建docker-compose" class="headerlink" title="3、搭建docker-compose"></a>3、搭建docker-compose</h1><h4 id="3-1-下载离线安装包"><a href="#3-1-下载离线安装包" class="headerlink" title="3.1 .下载离线安装包:"></a>3.1 .下载离线安装包:</h4><p>docker-compose下载地址：<a href="https://github.com/docker/compose/releases" title="docker-compose" target="_blank" rel="noopener">https://github.com/docker/compose/releases</a></p>
<p>选择自己的版本，我选的是当前最新的1.24.0版本，点击下载。下载后上传到服务器/usr/local/bin/目录下。!</p>
<p><img src="/.com//docker-compose.jpg" alt></p>
<a id="more"></a>
<h4 id="3-2-进入上述目录，对文件重命名，然后赋予执行权限："><a href="#3-2-进入上述目录，对文件重命名，然后赋予执行权限：" class="headerlink" title="3.2.进入上述目录，对文件重命名，然后赋予执行权限："></a>3.2.进入上述目录，对文件重命名，然后赋予执行权限：</h4><pre><code>cd  /usr/local/bin

mv  docker-compose-Linux-x86_64  docker-compose

sudo chmod +x docker-compose
</code></pre><h4 id="3-3-查看docker-compose版本号："><a href="#3-3-查看docker-compose版本号：" class="headerlink" title="3.3.查看docker-compose版本号："></a>3.3.查看docker-compose版本号：</h4><pre><code>docker-compose --version
</code></pre><h1 id="4、搭建harbor"><a href="#4、搭建harbor" class="headerlink" title="4、搭建harbor"></a>4、搭建harbor</h1><h4 id="4-1下载离线安装包："><a href="#4-1下载离线安装包：" class="headerlink" title="4.1下载离线安装包："></a>4.1下载离线安装包：</h4><pre><code>wget https://storage.googleapis.com/harbor-releases/harbor-offline-installer-v1.5.3.tgz
</code></pre><p>harbor下载地址：<a href="https://github.com/goharbor/harbor/releases" title="harbor  github下载" target="_blank" rel="noopener">https://github.com/goharbor/harbor/releases</a></p>
<p><img src="/.com//harbordownload.jpg" alt></p>
<h4 id="4-2解压离线安装包"><a href="#4-2解压离线安装包" class="headerlink" title="4.2解压离线安装包"></a>4.2解压离线安装包</h4><pre><code>tar -zxvf harbor-offline-installer-v1.5.3.tgz #解压离线安装包
mv harbor /opt/ #移到/opt目录下
cd /opt #进入到/opt目录
ll #查看目录内容
</code></pre><h4 id="4-3-配置Harbor"><a href="#4-3-配置Harbor" class="headerlink" title="4.3 配置Harbor"></a>4.3 配置Harbor</h4><pre><code>cd harbor #进入到harbor目录
ll #查看目录内容
</code></pre><p>编辑配置，并执行安装</p>
<pre><code>vim vim harbor.cfg #编辑配置文件
</code></pre><p>修改以下内容</p>
<pre><code>hostname = 192.168.35.11 #修改harbor的启动ip，这里需要依据系统ip设置
harbor_admin_password = admin123 #修改harbor的admin用户的密码
</code></pre><h4 id="4-4-安装Harbor"><a href="#4-4-安装Harbor" class="headerlink" title="4.4 安装Harbor"></a>4.4 安装Harbor</h4><pre><code>./prepare #配置Harbor
./install.sh #安装Harbor
</code></pre><h4 id="4-5-访问Harbor"><a href="#4-5-访问Harbor" class="headerlink" title="4.5 访问Harbor"></a>4.5 访问Harbor</h4><p>浏览器中，输入192.16.35.11，如下：<br><img src="/.com//harborui.jpg" alt></p>
<h4 id="4-6上传镜像到Harbor"><a href="#4-6上传镜像到Harbor" class="headerlink" title="4.6上传镜像到Harbor"></a>4.6上传镜像到Harbor</h4><p>配置镜像仓库的地址：</p>
<pre><code>vim /etc/docker/daemon.json
{
  &quot;live-restore&quot;: true,
  &quot;registry-mirrors&quot;: [&quot;https://5r7rw1qu.mirror.aliyuncs.com&quot;],
  &quot;insecure-registries&quot;: [&quot;192.16.35.11&quot;]
}
</code></pre><p>登录harbor:</p>
<pre><code>docke login 192.16.35.11
</code></pre><p><img src="/.com//dockerlogin.jpg" alt></p>
<p>上传成功可以在项目管理里面去查看：<br><img src="/.com//dockerpull.jpg" alt></p>
<p>参考博客：</p>
<p><a href="https://www.cnblogs.com/anxminise/p/9764221.html" title="harbor离线安装" target="_blank" rel="noopener">https://www.cnblogs.com/anxminise/p/9764221.html</a></p>
<p><a href="https://www.jianshu.com/p/6f9ce31b9aa7" title="docker-compose" target="_blank" rel="noopener">https://www.jianshu.com/p/6f9ce31b9aa7</a></p>
]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo常见操作</title>
    <url>/2019/04/17/hexo/</url>
    <content><![CDATA[<ul>
<li>hexo new “postName” #新建文章 </li>
</ul>
<ul>
<li><p>hexo new page “pageName” #新建页面 </p>
</li>
<li><p>hexo generate #生成静态页面至public目录 </p>
</li>
</ul>
<ul>
<li>hexo server #开启预览访问端口（默认端口4000，’ctrl + c’关闭 server）</li>
</ul>
<ul>
<li>hexo deploy #部署到GitHub </li>
</ul>
<ul>
<li>hexo help  # 查看帮助 </li>
</ul>
<ul>
<li>hexo version  #查看Hexo的版本</li>
</ul>
]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
